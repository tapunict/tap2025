{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Data Ingestion\"\n",
    "author: \"Salvo Nicotra\"\n",
    "format: \n",
    "    revealjs:\n",
    "        width: 1280\n",
    "        heigth: 800\n",
    "incremental: true  \n",
    "execute:\n",
    "  echo: true\n",
    "  warning: false\n",
    "theme: white\n",
    "chalkboard: true\n",
    "css: style.css\n",
    "smaller: true\n",
    "scrollable: true\n",
    "include-before: |\n",
    "    <img src=\"images/unict-logo.png\" class=\"custom-logo\" alt=\"Logo\">\n",
    "include-after: |\n",
    "      <div class=\"custom-footer\">\n",
    "        *** Technologies for advanced programming (TAP) - 2024/2025 ***\n",
    "      </div>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# What is Data Ingestion ?\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "<https://whatis.techtarget.com/definition/data-ingestion>\n",
    "\n",
    "- Data ingestion is the process of obtaining and importing data for immediate use or storage in a database. \n",
    "- To ingest something is to \"take something in or absorb something.\"\n",
    "::: \n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](images/dataingestionmeme.jpg)\n",
    "\n",
    "[Source](https://medium.com/ssense-tech/principled-data-engineering-part-i-architectural-overview-6d4bdf89b657)\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# A Market Perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![Data Integration Tools 2023](images/data-integration-magic-quadrant-2023.png){.fragment .r-scratch .smaller}\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![Integration Platform as a Service 2024](images/Figure_1_Magic_Quadrant_for_Integration_Platform_as_a_Service2024.png){.fragment .r-scratch .smaller}\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Some headlines\n",
    "- Informatica: \"Everybody’s ready for AI except your data\" <https://www.informatica.com/>\n",
    "- Workato: \"#1 iPaaS, with speed and power to orchestrate your organization’s data, apps, and processes\" <https://www.workato.com/>\n",
    "- Boomi: \"The trusted platform for AI-driven integration and automation.\" <https://www.boomi.com/>\n",
    "- Oracle: \"Oracle Cloud Infrastructure integration services connect any application and data source\" <https://www.oracle.com/integration/>\n",
    "- SAP: \"SAP Integration Suite is an integration platform-as-a-service (iPaaS) that helps you quickly integrate on-premise and cloud-based processes, services, applications, events, and data.\" <https://www.sap.com/products/technology-platform/integration-suite.html>\n",
    "- Microsoft: Bring your data into the era of AI <https://www.microsoft.com/en-us/microsoft-fabric>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# An M&A Story\n",
    "Alias how companies change to follow market needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### A new company in the data field has born\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "- Once upon a time, a company named Talend, has been founded with the idea the help organization to collect, transform, govern data accross different ecosystem.\n",
    "- Talend is known for its open-source approach, launching Talend Open Studio, which allowed users to build and deploy data integration jobs, and over time, expanded into broader data-related solutions like data quality, cloud integration, and governance.\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](images/data-ingestion.png)\n",
    "<https://www.talend.com/blog/2018/09/26/building-agile-data-lakes-with-robust-ingestion-and-transformation-frameworks-part-1/>\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Grow and acquire other companies to cover SMB market\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column .r-fit-text width=\"50%\"}\n",
    "\n",
    "> Last month Stitch became part of Talend. Talend is a global open source big data and cloud integration software company whose mission is \"to make your data better, more trustworthy, and more available to drive business value.\" That maps naturally to Stitch's mission \"to inspire and empower data-driven people.\"\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "- Talend offers a wide range of products to complement Stitch's frictionless SaaS ETL platform.\n",
    "- Extract data from 140+ popular sources to your warehouse or database in minutes — no coding required.\n",
    "![](https://i.imgflip.com/51lgul.jpg){.fragment}\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## And then acquired by a BI company\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "The combined entity has earned a leading position across multiple market categories. For seven years in a row, Gartner positioned Talend as a leader in its Magic Quadrant for Data Integration Tools, and a leader in its Magic Quadrant for Data Quality Solutions for five consecutive years. It has positioned Qlik as a leader in its Magic Quadrant for Analytics and Business Intelligence Platforms for 13 consecutive years. Additionally, Qlik has been named a leader in the IDC MarketScape: U.S. Business Intelligence and Analytics Platforms 2022 Vendor Assessment.\n",
    "\n",
    "[Source](https://cxotoday.com/press-release/qlik-acquires-talend-combining-its-best-in-class-data-integration-with-talends-leading-data-transformation-quality-and-governance-capabilities/)\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "![](https://www.informatec.com/sites/default/files/2023-08/Talend_QlikCompany_CircleLogo-Color_400x400.png)\n",
    "\n",
    "Jul 16, 2024\n",
    "\n",
    "<https://www.qlik.com/blog/qlik-talend-cloud-is-now-generally-available>\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## In a good company\n",
    "\n",
    "- IBM acquires Red Hat (2018)\n",
    "- Salesforce buys Tableau (2019)\n",
    "- Google Cloud buys Looker (2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Data Ingestion vs Data Integration\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "> Data ingestion is similar to, but distinct from, the concept of data integration, which seeks to integrate multiple data sources into a cohesive whole. With data integration, the sources may be entirely within your own systems; on the other hand, data ingestion suggests that at least part of the data is pulled from another location (e.g. a website, SaaS application, or external database).\n",
    "\n",
    "[Source](https://www.integrate.io/blog/data-ingestion-vs-etl/#:~:text=With%20data%20integration%2C%20the%20sources,application%2C%20or%20external%20database)\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](https://i.imgflip.com/51n8l0.jpg)\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Data Ingestion Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## 1. Data Sources\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "- The first step in data ingestion is to identify and understand the data sources that are relevant to the business needs.\n",
    "- These sources can vary widely depending on the type of data (structured, semi-structured, or unstructured) and the business domain.\n",
    "\n",
    "::: {.callout-important}\n",
    "Data needs to be accessible (permessions/reachability)\n",
    ":::\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](images/griffinfirehose.gif)\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## 2. Data Collection / Acquisition\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "- Data collection is the process of gathering information from various sources to use it for further analysis, processing, or storage.\n",
    "- In the context of data ingestion, data collection involves the initial step of retrieving raw data from multiple sources, which can then be transformed, validated, and loaded into a data storage or processing system.\n",
    "- Different strategies are used to collect data, based on the nature of the data source and the business requirements\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](images/sevendrawfs.png)\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Data collection methods\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .smaller .column width=\"50%\"}\n",
    "**Batch**\n",
    "\n",
    "- Batch collection involves gathering and processing data at regular intervals (e.g. hourly, daily).\n",
    "- Large datasets are retrieved, and multiple records are collected in a single batch. \n",
    "\n",
    "![](images/batch_data_collection.webp){.fragment .r-scratch width=\"250\"}\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "::: {.fragment .smaller .column width=\"50%\"}\n",
    "**Streaming**\n",
    "\n",
    "- Streaming data collection is the continuous ingestion of data in real time, where data is collected as soon as it is generated.\n",
    "- Data flows continuously from the source to the destination, allowing real-time processing and analysis.\n",
    "  \n",
    "![](images/stream_data_collection.webp){.fragment .r-scratch width=\"250\"}\n",
    "\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## 3. Data Validation \n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "- **Data Cleaning**: Identify and correct inaccuracies in the data. This can involve handling missing values, removing duplicates, or resolving inconsistencies.\n",
    "- **Schema Validation**: Ensure that the incoming data complies with the predefined schema in terms of structure, types, and constraints.\n",
    "- **Quality Checks**: Check for data integrity, quality, and completeness.\n",
    "\n",
    "::: {.callout-warning}\n",
    "Validation can be expensive and not always applicable\n",
    ":::\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](images/data-validation.webp){.r-scratch width=\"80%\" }\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## 4. Data Transformation\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "- Data Enrichment: Enhance data by combining it with additional information from other sources (e.g., adding geographical metadata to GPS coordinates).\n",
    "- Normalization & Aggregation: Normalize data into consistent units or aggregate it (e.g., summarizing sales data by month).\n",
    "- Filtering: Filter out unwanted or irrelevant data.\n",
    "\n",
    "::: {.callout-warning}\n",
    "Transformation is an optional step, the original idea of schema on read implies raw data non filtered, however this requires space and not always bring value\n",
    ":::\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](images/data-tranformation.webp){.r-scratch width=\"80%\" }\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## 5. Data Loading (Destination-Sink)\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"40%\"}\n",
    "\n",
    "- Once the method is defined (batch/real time), start the process to tranfer the data\n",
    "- Data can be sent to different types of destination (database/wharehouse, data lake, ...)\n",
    "- Data can be loaded incrementaly or full load)\n",
    "- This is the moment where effectively data are ingested in our system\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"60%\"}\n",
    "{{< video https://packaged-media.redd.it/zaag9rsteub81/pb/m2-res_1080p.mp4?m=DASHPlaylist.mpd&v=1&e=1728849600&s=3b8ea9307cd329992bdbb7a301e949b25f4453d3 >}}\n",
    "[Source](https://www.reddit.com/r/memes/comments/s4j1cu/loading_bars/#lightbox)\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## 6. Monitoring and Logging\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "- Error Handling: Implement mechanisms for error handling and retries in case of failure during ingestion.\n",
    "- Logging: Maintain logs for every step, including data source connection, parsing issues, or schema violations.\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "![[Nics Meme](https://imgflip.com/i/96jyfj)](https://i.imgflip.com/96jyfj.jpg)\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## 7. Automation and Scheduling\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "\n",
    "  \n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "- Automating Pipelines: Use tools and platforms to automate data ingestion.\n",
    "- Scheduling: Schedule periodic ingestion tasks for batch processes.\n",
    "- Often these tools act like an agent connected to the data generation\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "![](images/microagent.png){.r-scratch width=\"80%\" }\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## 8. Security and Compliance\n",
    "\n",
    "::::{.columns}\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "- Data Encryption: Encrypt sensitive data both in transit and at rest.\n",
    "- Access Controls: Implement access controls and ensure only authorized users can ingest or view the data.\n",
    "- Compliance: Ensure compliance with regulations like GDPR, HIPAA, or any domain-specific regulations.\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.fragment .column width=\"50%\"}\n",
    "\n",
    "![[NicsMeme](https://imgflip.com/i/96k2xd)](https://i.imgflip.com/96k2xd.jpg){width=\"50%\"}\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Data Ingestion \n",
    "\n",
    "![It's about moving data - and especially unstructured data ](images/awstruck.gif){.fragment} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### from where it is originated\n",
    "![](images/batcave.jpg){.fragment}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### into a system where it can be stored and analyzed.\n",
    "![](images/lestrange.jpg){.fragment}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "# Data Ingestion is the beginning of a Data Pipeline{background-color=\"black\" background-image=\"https://i.ytimg.com/vi/kGT4PcTEPP8/maxresdefault.jpg\" background-size=\"80%\" background-opacity=\"0.5\"}\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=kGT4PcTEPP8 >}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Data Ingestion Tools\n",
    "\n",
    "<iframe width=\"768\" height=\"432\" src=\"https://miro.com/app/live-embed/uXjVMZ6qq8o=/?moveToViewport=-1896,-1206,3105,1590&embedId=293799998045\" frameborder=\"0\" scrolling=\"no\" allow=\"fullscreen; clipboard-read; clipboard-write\" allowfullscreen></iframe>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": "true",
   "footer": "<div class=\"tap-footer\"> *** Technologies for advanced programming (TAP) - 2024 ***</div>",
   "header": "<div class=\"tap-header\"></div>",
   "scroll": true,
   "theme": "white"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
